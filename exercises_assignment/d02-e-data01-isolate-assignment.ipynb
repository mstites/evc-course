{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905d202f",
   "metadata": {},
   "source": [
    "# Data: Isolating Data\n",
    "\n",
    "*Purpose*: One of the keys to a successful analysis is the ability to *focus* on particular topics. When analyzing a dataset, our ability to focus is tied to our facility at *isolating data*. In this exercise, you will practice isolating columns with `tf_select()`, picking specific rows with `tf_filter()`, and sorting your data with `tf_arrange()` to see what rises to the top.\n",
    "\n",
    "*Aside*: The data-management verbs in grama are heavily inspired by the [dplyr](https://dplyr.tidyverse.org/) package in the R programming langauge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772427d",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee809b9",
   "metadata": {},
   "source": [
    "We'll use the `nycflights13` package in this exercise: This is a dataset of flights involving the New York City area during 2013.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nycflights13 import flights as df_flights\n",
    "df_flights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ff21e4",
   "metadata": {},
   "source": [
    "# The DataFrame Object\n",
    "\n",
    "The variable `df_flights` above is a *DataFrame*; a way of storing data in Python.\n",
    "\n",
    "*Aside*: The DataFrame class is provided by the [Pandas](https://pandas.pydata.org/docs/index.html) package, but we will use [Grama](https://github.com/zdelrosario/py_grama) to work with DataFrames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f1edd",
   "metadata": {},
   "source": [
    "## Head and Tail\n",
    "\n",
    "Looking at an entire DataFrame is usually overwhelming; it is useful to be able to focus on a small subset of the data. One of our most basic tools is to get the first or last few rows of a DataFrame, which we can do with `DataFrame.head(n)` and `DataFrame.tail(n)`. These functions are called with the following syntax:\n",
    "\n",
    "```python\n",
    "df_flights.head(10)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5830cb",
   "metadata": {},
   "source": [
    "### __q1__ Get the tail of a DataFrame\n",
    "\n",
    "Get the last 10 rows of `df_flights`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf54f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Get the last 10 rows of df_flights\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66fc9b6",
   "metadata": {},
   "source": [
    "# Piping\n",
    "\n",
    "Often, when carrying out studies with data, we want to perform *multiple* operations on the same dataset. We could do this by assigning *intermediate variables*, such as a temporary DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "df_tmp = df_flights.head(10) # Temporary DataFrame\n",
    "df_tmp.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b471d6",
   "metadata": {},
   "source": [
    "Alternatively, we could *chain* together calls:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64243837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "df_flights.head(10).tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4370ef8b",
   "metadata": {},
   "source": [
    "Rather than these two approaches, using [grama](https://github.com/zdelrosario/py_grama) we can form a *data pipeline* using the pipe operator `>>`. The following code demonstrates the use of the pipe operator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_flights\n",
    "    >> gr.tf_head(10)\n",
    "    >> gr.tf_tail(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d0b34",
   "metadata": {},
   "source": [
    "It's useful to think of the pipe operator as the English word \"then\". This allows us to translate code:\n",
    "\n",
    "```python\n",
    "(\n",
    "    df_flights\n",
    "    >> gr.tf_head(10)\n",
    "    >> gr.tf_tail(5)\n",
    ")\n",
    "```\n",
    "\n",
    "into something looking like a plain-language sentence\n",
    "\n",
    "```\n",
    "(\n",
    "    Start with df_flights\n",
    "    \"then\" take the first 10\n",
    "    \"then\" take the last 5.\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0488b",
   "metadata": {},
   "source": [
    "*Aside*: Most of the grama functions we'll use in this exercise start with the `tf_` prefix; this means they take in a DataFrame and return a DataFrame (they `tr`ansform data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9939b0",
   "metadata": {},
   "source": [
    "### __q2__ Convert to piped code\n",
    "\n",
    "Convert the following code to a pipe-enabled version.\n",
    "\n",
    "*Note*: The pipe-enabled version of `DataFrame.head()` is `tf_head()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Convert the following code to pipe-enabled form\n",
    "df_flights.head(10)\n",
    "\n",
    "(\n",
    "    df_flights\n",
    "    # Complete this code\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb07172d",
   "metadata": {},
   "source": [
    "# Column Selection\n",
    "\n",
    "The grama function `gr.tf_select()` allows us to select particular columns, which is helpful for getting a more \"focused\" view of a datset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f19be",
   "metadata": {},
   "source": [
    "### __q3__ Select particular columns\n",
    "\n",
    "Select the columns \"month\", \"day\", \"origin\", and \"dest\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Select the columns \"month\", \"day\", \"origin\", and \"dest\"\n",
    "(\n",
    "    df_flights\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7675341",
   "metadata": {},
   "source": [
    "## Selection Helpers\n",
    "\n",
    "The `gr.tf_select()` function is helpful, but it is made *extremely powerful* with a few selection helpers. Rather than specify specific column names, we can use helpers to *match* names that satisfy different criteria.\n",
    "\n",
    "Here are a few of the most important selection helpers: \n",
    "\n",
    "| Helper | Selects |\n",
    "|---|---|\n",
    "| `gr.starts_with(s)` | Columns that start with string `s` |\n",
    "| `gr.ends_with(s)` | Columns that end with string `s` |\n",
    "| `gr.contains(s)` | Columns that contain the string `s` |\n",
    "| `gr.everything()` | All columns *not already selected* |\n",
    "\n",
    "For instance, the following code will select all the columns whose name starts with `\"dep_\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_flights\n",
    "    >> gr.tf_select(gr.starts_with(\"dep_\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb7439",
   "metadata": {},
   "source": [
    "### __q4__ Match columns\n",
    "\n",
    "Select only those columns whose name ends with `\"_time\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Select only those columns whose name ends with \"_time\"\n",
    "(\n",
    "    df_flights\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23043976",
   "metadata": {},
   "source": [
    "## Re-arranging columns with `gr.everything()`\n",
    "\n",
    "The `gr.everything()` helper may seem silly, but it is actually *extremely* useful; since the everything helper selects all columns *not already selected*, we can use it to re-arrange the columns in a DataFrame for a more convenient view. For instance, we can bring a few columns closer together to aid in column comparisons, as the following code demonstrates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d200940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    df_flights\n",
    "    >> gr.tf_select(\"origin\", \"dest\", \"distance\", gr.everything())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d0077",
   "metadata": {},
   "source": [
    "### __q5__ Re-arrange columns\n",
    "\n",
    "Re-arrange the columns to place `dest, origin, carrier` at the left, but retain all other columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Bring \"dest\", \"origin\", and \"carrier\" to the left,\n",
    "# but keep all other columns\n",
    "(\n",
    "    df_flights\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b59e3",
   "metadata": {},
   "source": [
    "# Row Filtering\n",
    "\n",
    "Just as we can select particular columns, we can *filter* to obtain particular rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49120493",
   "metadata": {},
   "source": [
    "## Accessing column values\n",
    "\n",
    "To access a single column of a DataFrame, we can use bracket `[]` notation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16171f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_flights[\"origin\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4edf4",
   "metadata": {},
   "source": [
    "Note that returns a different datatype: a Pandas *series*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a22c2f1",
   "metadata": {},
   "source": [
    "## Making a comparison\n",
    "\n",
    "Remember that we have the following comparison operators:\n",
    "\n",
    "| Symbol | Compares |\n",
    "|---|---|\n",
    "| `x < y` | `x` less than `y` |\n",
    "| `x <= y` | `x` less than or equal to `y` |\n",
    "| `x > y` | `x` greater than `y` |\n",
    "| `x >= y` | `x` greater than or equal to `y` |\n",
    "| `x == y` | `x` (exactly) equals `y` |\n",
    "|          | Note that `==` works for strings too! |\n",
    "| `x = y` | Error! |\n",
    "\n",
    "With a single column, we can make a comparison against a desired value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_flights[\"origin\"] == \"JFK\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf38fc",
   "metadata": {},
   "source": [
    "The code above gives us `True` when the `\"origin\"` is `\"JFK\"`, and `False` when it is not.\n",
    "\n",
    "## Filtering using comparisons\n",
    "\n",
    "These `True`/`False` values are useful, because we can use them to *filter* to only those rows where the comparison yields `True`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_flights\n",
    "    >> gr.tf_filter(df_flights[\"origin\"] == \"JFK\")\n",
    "    # Show that the \"origin\" is indeed \"JFK\"\n",
    "    >> gr.tf_select(\"origin\", gr.everything())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45303a",
   "metadata": {},
   "source": [
    "### __q6__ Find the early departures\n",
    "\n",
    "Use `gr.tf_filter()` to find all the flights that left early.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Filter for only those rows with a negative \"dep_delay\"\n",
    "(\n",
    "    df_flights\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348e8c2",
   "metadata": {},
   "source": [
    "## The data pronoun `DF`\n",
    "\n",
    "Way back at the beginning of this notebook, you may have noticed this line of code:\n",
    "\n",
    "```python\n",
    "DF = gr.intention()\n",
    "```\n",
    "\n",
    "This assigned the \"data pronoun\" to the variable `DF`. This pronoun can be used inside grama functions to refer to the data *as it is* at any stage in the pipeline. Rather than:\n",
    "\n",
    "```python\n",
    "(\n",
    "    df_flights\n",
    "    >> gr.tf_filter(df_flights[\"dep_delay\"] < 0)\n",
    ")\n",
    "```\n",
    "\n",
    "we instead write\n",
    "\n",
    "```python\n",
    "(\n",
    "    df_flights\n",
    "    >> gr.tf_filter(DF[\"dep_delay\"] < 0)\n",
    ")\n",
    "```\n",
    "\n",
    "The data pronoun `DF` is really just an alias for the DataFrame, so we can still use bracket notation `[]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f4acc",
   "metadata": {},
   "source": [
    "The data pronoun `DF` is not just convenient; it is *necessary* to make some operations work! Imagine we wanted to find all cases that satisfy both `dep_delay < 0` and `arr_delay < 0`. Consider the following code:\n",
    "\n",
    "```python\n",
    "(\n",
    "    df_flights\n",
    "    # This filter works properly\n",
    "    >> gr.tf_filter(df_flights[\"dep_delay\"] < 0)\n",
    "    # We now have fewer rows! The next filter will fail\n",
    "    >> gr.tf_filter(df_flights[\"arr_delay\"] < 0)\n",
    ")\n",
    "```\n",
    "\n",
    "The data pronoun `DF` allows us to refer to the data *as it is* in the pipeline; this resolves the issue with having fewer rows in the second filter. You'll get a chance to fix this code in the next task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35191f69",
   "metadata": {},
   "source": [
    "### __q7__ Use `DF` to fix this code\n",
    "\n",
    "Use the data pronoun `DF` to fix the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46cdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Fix this code using the data pronoun DF\n",
    "# Uncomment to begin this task\n",
    "# (\n",
    "#     df_flights\n",
    "#     >> gr.tf_filter(df_flights[\"dep_delay\"] < 0)\n",
    "#     >> gr.tf_filter(df_flights[\"arr_delay\"] < 0)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd2ae9",
   "metadata": {},
   "source": [
    "# Arranging\n",
    "\n",
    "Filtering is particularly helpful when combined with *sorting*; we can sort on any column using the function `gr.tf_arrange()`. For instance, the following code sorts by the `\"distance\"`, pulling the shortest flights to the top of the DataFrame:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20368e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_flights\n",
    "    # Sorts from smallest to largest\n",
    "    >> gr.tf_arrange(DF[\"distance\"])\n",
    "    # Inspect the route\n",
    "    >> gr.tf_select(\"distance\", \"origin\", \"dest\", gr.everything())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3a612",
   "metadata": {},
   "source": [
    "We can also reverse the order of the sort with the `gr.desc()` helper, as shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_flights\n",
    "    # Sorts from largest to smallest (*desc*ending)\n",
    "    >> gr.tf_arrange(gr.desc(DF[\"distance\"]))\n",
    "    # Inspect the route\n",
    "    >> gr.tf_select(\"distance\", \"origin\", \"dest\", gr.everything())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a1773",
   "metadata": {},
   "source": [
    "### __q8__ Find the earliest departures\n",
    "\n",
    "Find the top 10 *earliest* departures. How early did these depart? Do these early departures have anything in common?\n",
    "\n",
    "*Hint*: You will need to combine functions to accomplish this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50103bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Find the top 10 earliest departures\n",
    "(\n",
    "    df_flights\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce9169",
   "metadata": {},
   "source": [
    "# Isolating to answer questions\n",
    "\n",
    "Before we close this exercise, let's use these data isolation tools to answer a real question about the dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9b243",
   "metadata": {},
   "source": [
    "### __q9__ What are these data for?\n",
    "\n",
    "What are these data for? In particular, in what way are they \"focused on the NYC area\"? Complete the following tasks, and answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b095c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Filter to only those cases where the destination airport\n",
    "# is one of \"JFK\", \"LGA\", or \"EWR\"\n",
    "df_q9dest = (\n",
    "    df_flights\n",
    "\n",
    ")\n",
    "\n",
    "# NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    df_q9dest.shape[0] == 1, \\\n",
    "    \"Incorrect filter\"\n",
    "\n",
    "df_q9dest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Filter to only those cases where the origin airport\n",
    "# is one of \"JFK\", \"LGA\", or \"EWR\"\n",
    "df_q9origin = (\n",
    "    df_flights\n",
    "\n",
    ")\n",
    "\n",
    "# NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    df_q9origin.shape[0] == df_flights.shape[0], \\\n",
    "    \"Incorrect filter\"\n",
    "\n",
    "df_q9origin "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca905394",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- How many rows have either \"JFK\", \"LGA\", or \"EWR\" as their *destination*?\n",
    "  - (Your response here)\n",
    "- How many rows have either \"JFK\", \"LGA\", or \"EWR\" as their *origin*?\n",
    "  - (Your response here)\n",
    "- Would we be answer questions related to flights *entering* the NYC area using this dataset?\n",
    "  - (Your response here)\n",
    "- In what sense is this dataset \"focused on NYC\"?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9346b7",
   "metadata": {},
   "source": [
    "*Aside*: Data are not just numbers. Data are *numbers with context*. Every dataset is put together for some reason. This reason will inform what observations (rows) and variables (columns) are *in the data*, and which are *not in the data*. Conversely, thinking carefully about what data a person or organization bothered to collect---and what they ignored---can tell you something about the *perspective* of those who collected the data. Thinking about these issues is partly what separates __data science__ from programming or machine learning. (`end-rant`)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
